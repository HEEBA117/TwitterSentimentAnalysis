{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='black'>Twitter sentiment classification using Apache Spark:</font>\n",
    "#### <font color ='black'>This project is done by\n",
    "- Nitin Surya (nsurya3)\n",
    "- Heeba Mohammed Ali (hmoham23)\n",
    "\n",
    "Abstract: Sentiment analysis is done on the tweets using different machine learning techniques in Apache Spark. The faeatures are extracted from data and supervised learning models are built. The model automatically classifies the tweets as positive or negative. We have used three techniques in our project namely Naive bayes, Logistic Regression and Decision Tree Modeling. We have observed the training accuracy, 5-fold validation accuracy and test accuracy,  F1 measure , precision and recall  and compared them to identify the best classifier amongst these classifiers.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'black'> Application dependencies </font>\n",
    "<font color = 'black'>\n",
    "<pre>\n",
    "- Jupyter\n",
    "- NLTK\n",
    "- Pyspark\n",
    "- Numpy\n",
    "- Matplotlib\n",
    "</pre>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'black'>1. Tweet Processing: </font>\n",
    "<font color = 'black' > \n",
    "a.\tAll the tweets are passed to a function called get_cleaned_tweet()<br>\n",
    "b.\tGet_cleaned_tweet() internally calls the get_cleaned_word() method which cleans the individual words of the tweet<br>\n",
    "    &nbsp;&nbsp;&nbsp;i. Uses Porterâ€™s stemmer algorithm for stemming with NLTK library<br>\n",
    "    &nbsp;&nbsp;&nbsp;ii. Stop words are removed by checking with the custom stop word file, from HW3<br>\n",
    "    &nbsp;&nbsp;&nbsp;iii. All the words were converted to lower case for simplicity<br>\n",
    "    &nbsp;&nbsp;&nbsp;iv. Punctuations were stripped<br>\n",
    "    &nbsp;&nbsp;&nbsp;v. Multiple occurences of character are replaced by 2 occurences<br>\n",
    "    &nbsp;&nbsp;&nbsp;vi. Hashtags were replaced in the beginning of word. @ mentiones were replaced with 'AT_USER'<br>\n",
    "    &nbsp;&nbsp;&nbsp;vii. 'http' etc links replaced with 'URL'<br>\n",
    "    &nbsp;&nbsp;&nbsp;viii. Only words greater than 1 character were included<br>\n",
    "c.\tThe cleaned text is passed as a list to feature extraction function<br>\n",
    "d.\tFeature extraction & Transformation is done using:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i.\tpyspark.mllib.feature.HashingTF<br>\n",
    "e.\tThis is converted into a labelled point and given to the spark context which converts it into an RDD vector<br>\n",
    "f.\tThe words are the individual features<br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'black'> 2. Feature Space</font>\n",
    "<font color = 'black'>\n",
    "a. The feature space is the set of all words in the tweets<br>\n",
    "b. We are considering unigrams<br>\n",
    "c. The size of the feature space:<br>\n",
    "        &nbsp;&nbsp;&nbsp;i. Entire set of words for NB and LOG<br>\n",
    "        &nbsp;&nbsp;&nbsp;ii. 100 features for DT<br>\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'black'>3. Experiment Results: </font>\n",
    "<font color = 'black'>\n",
    "<table>\n",
    "<tr>\n",
    "<td>Algorithm</td>\n",
    "<td>Training accuracy</td>\n",
    "<td>5 fold cross validation accuracy</td>\n",
    "<td>Test accuracy</td>\n",
    "<td>Avg precision</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>NB</td>\n",
    "<td> 83% </td>\n",
    "<td> 74% </td>\n",
    "<td> 78% </td>\n",
    "<td> 0.83</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>LOG</td>\n",
    "<td> 70% </td>\n",
    "<td> 71% </td>\n",
    "<td> 70% </td>\n",
    "<td> 0.69</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>DT</td>\n",
    "<td> 61% </td>\n",
    "<td> 60% </td>\n",
    "<td> 59% </td>\n",
    "<td> </td>\n",
    "</tr>\n",
    "</table>\n",
    "</font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'black'> Evaluation Metrics details </font>\n",
    "<font color = 'black'>\n",
    "<pre>\n",
    "1. Confusion Matrix:\n",
    " - \"True positive\" indicate the prediction model correctly suggested a tweet to be positive.\n",
    " - \"True negative\" indicate the prediction model correctly suggested a tweet to be negative.\n",
    " - \"False positive\" indicate the prediction model incorrectly suggested a tweet to be positive.\n",
    " - \"False negative\" indicate the prediction model incorrectly suggested a tweet to be negative.\n",
    "\n",
    "2. Precision:\n",
    " - The correct tweet, out of all the tweets predicted as positive.\n",
    "</pre>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'black'> Results </font>\n",
    "<font color = 'black'>\n",
    "<pre>\n",
    "After trying Naive bayes, Logistic regression and Decision trees, it was observed that Naive bayes performs best,\n",
    "as it gave the highest accuracy and precision.\n",
    "\n",
    "It was also observed that, no significant overfitting was observed, as the accuracy in the training set was\n",
    "similar to the test set\n",
    "</pre>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"first spark based notebook\")\n",
    "\n",
    "NETID = \"nsurya3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline   # used to display graphs inside the jupyter\n",
    "\n",
    "# classifiers and regression models used\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel, LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "# feature extraction options\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "# evaluation metrics for getting precision recall, f1 measure, AUC ROC etc.\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# for graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> \n",
    "<pre>\n",
    "Cleaning Pre-steps:\n",
    "1. The stop words file is read to make a stop word corpus to check for stop words.\n",
    "2. The NLTK library functions are used to identify Punctuations\n",
    "3. Porters stemmer algorithm is initilaized for stemming\n",
    "</pre> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words_file = open('./data/stopwords.txt')\n",
    "stop_words = []\n",
    "\n",
    "for word in stop_words_file:\n",
    "    stop_words.append(word.strip())\n",
    "\n",
    "# Module-level global variables for the `tokenize` function below\n",
    "PUNCTUATION = set(string.punctuation)\n",
    "STOPWORDS = set(stop_words)\n",
    "STEMMER = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'black'>1. displayMetrics function:</font><br/>\n",
    "<font color = 'black'> This function computes and displays accuracy of the classifier, Precision, Recall, Fmeasure, Area under ROC, Confusion Matrix</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns: accuracy, truePositiveRate, falsePositiveRate\n",
    "def displayMetrics(metrics, predictionAndLabel, test, showMetrics = True):\n",
    "    accuracy = (1.0 * predictionAndLabel.filter(lambda x: x[0] == x[1]).count() / test.count())\n",
    "\n",
    "    if(showMetrics):\n",
    "        print('Confusion Matrix:')\n",
    "        print(metrics.confusionMatrix().toArray())\n",
    "        print(\"Accuracy = %s\" % accuracy)\n",
    "        print(\"Precision = %s\" % metrics.precision())\n",
    "        # Area under precision-recall curve\n",
    "        print(\"Recall = %s\" % metrics.recall())\n",
    "        print(\"fMeasure = %s\" % metrics.fMeasure(0.0))\n",
    "        print()\n",
    "\n",
    "    return accuracy, metrics.truePositiveRate(0.0), metrics.falsePositiveRate(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'black'>2. get_clean_word function:</font><br/>\n",
    "<font color = 'black'> This function is called to clean the individual words (features) of the tweet during feature extraction process</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns a cleaned, and simple letters based word\n",
    "def get_clean_word(word):    \n",
    "    while(len(word) > 0 and not (word[0].isalpha() or word[0] in ('#', '@', ':', ';'))): # removing numbers and special chars from beginning\n",
    "        word = word[1:]\n",
    "    \n",
    "    if(len(word) > 0):\n",
    "        if(word[0] == '@'): # is user ref\n",
    "            return \"AT_USER\"\n",
    "        elif(word.startswith(\"http:\") or word.startswith(\"https:\") or word.startswith(\"www\")): # URLs\n",
    "            return 'URL'\n",
    "        elif(word[0] == '#'): # tags\n",
    "            return word[1:]\n",
    "        elif(word[0] in [';', ':']):\n",
    "            return word\n",
    "\n",
    "    while(len(word) > 0 and not word[-1].isalpha()): # removing numbers and special chars from end\n",
    "        word = word[0:-1]\n",
    "\n",
    "    if(len(word) > 0 and (word[0] == '@' or word[0] == '#' or word.startswith(\"http:\") or word.startswith(\"https:\"))):\n",
    "        return \"\"\n",
    "    \n",
    "    # removing continuous characters e.g. awwww -> aww\n",
    "    temp_word = word\n",
    "    word_len = len(temp_word)\n",
    "    prev_index, word = 0, \"\"\n",
    "    for index, char in enumerate(temp_word):\n",
    "        if index == 0:\n",
    "            word = word + char\n",
    "            continue\n",
    "        \n",
    "        if(temp_word[index - 1] == temp_word[index]):\n",
    "            continue\n",
    "        else:\n",
    "            if(index - prev_index >= 2):\n",
    "                word = word + temp_word[index-1]\n",
    "\n",
    "            prev_index = index\n",
    "            word = word + char\n",
    "\n",
    "    # for last character handling\n",
    "    if(len(temp_word) - 1 - prev_index >= 2):\n",
    "        word = word + temp_word[index-1]\n",
    "    \n",
    "    word = STEMMER.stem(word) # finally stemming the word using nltk stemmer\n",
    "\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'black'>3. get_cleaned_tweet function:</font><br/>\n",
    "<font color = 'black'> This function returns LabeledPoint Hashedtf of final cleaned words, and polarity.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns array of final cleaned words, the original json text and the complete tweet json parsed\n",
    "def get_cleaned_tweet(tweet_csv_line, get_id = False):\n",
    "    tweet_csv_line = tweet_csv_line.strip().split(',')\n",
    "    tweet_obj = ','.join(tweet_csv_line[5:])[1:-1]\n",
    "    label = float(tweet_csv_line[0].strip('\"'))\n",
    "    json_format=False\n",
    "    tweet_json = {'text': tweet_obj}\n",
    "    tweet_text = tweet_obj\n",
    "\n",
    "    parsed_tweet = tweet_text.strip().replace(',', ' ').split()\n",
    "    final_words = []\n",
    "    for word in parsed_tweet:\n",
    "        if word in STOPWORDS:\n",
    "            continue\n",
    "\n",
    "        word = get_clean_word(word)\n",
    "        if len(word) > 2:\n",
    "            final_words.append(word)\n",
    "\n",
    "    words_vector = hashingTF.transform(final_words)\n",
    "    labelled_point = LabeledPoint(label, words_vector)\n",
    "    if(get_id):\n",
    "        return [tweet_obj, labelled_point]\n",
    "    else:\n",
    "        return labelled_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'black'>4. Naive bayes function</font><br/>\n",
    "<font color = 'black'> Creates a model using training data if not present.\n",
    "Setting the metrics and preciation and label variables</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naiveBayes(training, test, model=None):\n",
    "    if(model == None):\n",
    "        model = NaiveBayes.train(training, 1.0)\n",
    "    predictionAndLabel = test.map(lambda p: (float(model.predict(p.features)), p.label))\n",
    "    metrics = MulticlassMetrics(predictionAndLabel)\n",
    "    return displayMetrics(metrics, predictionAndLabel, test), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'>Training the model with the train data</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 10089.   1938.]\n",
      " [  2249.   9932.]]\n",
      "Accuracy = 0.827040647719762\n",
      "Precision = 0.827040647719762\n",
      "Recall = 0.827040647719762\n",
      "fMeasure = 0.8281551405704904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF()\n",
    "data = sc.textFile('./data/train.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "#idf = IDF()\n",
    "#model = idf.fit(data)\n",
    "training, test = data, data.sample(False, 0.3)\n",
    "(acc_val, actual, predication), naiveBayesModel = naiveBayes(training, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'>Testing the model with the test data</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 140.   37.]\n",
      " [  41.  141.]]\n",
      "Accuracy = 0.7827298050139275\n",
      "Precision = 0.7827298050139275\n",
      "Recall = 0.7827298050139275\n",
      "fMeasure = 0.782122905027933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF()\n",
    "testcsv_data = sc.textFile('./data/test.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "(acc_val, actual, predication), model = naiveBayes([], testcsv_data, naiveBayesModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> 5 fold validation of a naive Bayes model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-e18e63a167cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0macc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredication\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0macc_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc_sum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macc_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-b8f3bc5a3def>\u001b[0m in \u001b[0;36mnaiveBayes\u001b[1;34m(training, test, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpredictionAndLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMulticlassMetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictionAndLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdisplayMetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictionAndLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-119-2a9bf69abd8d>\u001b[0m in \u001b[0;36mdisplayMetrics\u001b[1;34m(metrics, predictionAndLabel, test, showMetrics)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshowMetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion Matrix:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy = %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision = %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/etc/spark/python/pyspark/mllib/evaluation.py\u001b[0m in \u001b[0;36mconfusionMatrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mordered\u001b[0m \u001b[0mby\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"confusionMatrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1.4.0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/etc/spark/python/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, name, *a)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;34m\"\"\"Call method of java_model\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/etc/spark/python/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/etc/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m    813\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m/etc/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/etc/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[1;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF()\n",
    "data = sc.textFile('./data/train.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "kfold_test = data.randomSplit([0.2,0.2,0.2,0.2,0.2])\n",
    "acc_sum = 0\n",
    "for i in range(5):\n",
    "    test_set = kfold_test[i]\n",
    "    combined_set = None\n",
    "    for j in range(5):\n",
    "        if j != i:\n",
    "            if(combined_set != None):\n",
    "                combined_set = combined_set + kfold_test[j]\n",
    "            else:\n",
    "                combined_set = kfold_test[j]\n",
    "\n",
    "    training = combined_set\n",
    "    test = test_set\n",
    "    (acc_val, actual, predication), model = naiveBayes(training, test)\n",
    "    acc_sum = acc_sum + acc_val\n",
    "\n",
    "print(\"avg accuracy = {}\".format(acc_sum/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'black'>5. Logistic Regression function</font><br/>\n",
    "<font color = 'black'> Train a Logistic Regression model if not present from the parsed data. Also create the metrics and prediction and label variable</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "def logisticRegression(parsedData, test, model=None, showMetrics = True):\n",
    "    if(model == None):\n",
    "        model = LogisticRegressionWithLBFGS.train(parsedData)\n",
    "    predictionAndLabel = test.map(lambda p: (float(model.predict(p.features)), p.label))\n",
    "    metrics = MulticlassMetrics(predictionAndLabel)\n",
    "    return displayMetrics(metrics, predictionAndLabel, test, showMetrics), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> Training the model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 7321.  3607.]\n",
      " [ 3137.  7876.]]\n",
      "Accuracy = 0.6926302356319219\n",
      "Precision = 0.6926302356319219\n",
      "Recall = 0.6926302356319219\n",
      "fMeasure = 0.684653511643131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures=600)\n",
    "data = sc.textFile('./data/train.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "parsedData, test = data, data.randomSplit([0.3, 0.8])[0]\n",
    "(acc_val, actual, predication), logistic_model = logisticRegression(parsedData, test)\n",
    "model = logistic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> Testing the model on train data</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 115.   62.]\n",
      " [  43.  139.]]\n",
      "Accuracy = 0.7075208913649025\n",
      "Precision = 0.7075208913649025\n",
      "Recall = 0.7075208913649025\n",
      "fMeasure = 0.6865671641791045\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiIiIiIiIiIiIlIo/j/48Td8SUFv9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1482714f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures=600)\n",
    "testcsv_data = sc.textFile('./data/test.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "(acc_val, actual, predication), model = logisticRegression([], testcsv_data, model)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "for i in np.arange(0, 1, 0.05):\n",
    "    model.setThreshold(i)\n",
    "    (acc_val, actual, predication), model = logisticRegression([], testcsv_data, model, False)\n",
    "    x_val.append(actual)\n",
    "    y_val.append(predication)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.plot(y_val, x_val, label='AUC')\n",
    "\n",
    "#plt.plot([0,1],[0,1],'r--')\n",
    "#plt.xlim([0,1])\n",
    "#plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> 5 fold validation of a Logistic Regression model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6927790763787984\n",
      "Area under PR = 0.7716010159197145\n",
      "Area under ROC = 0.6927310577926814\n",
      "Accuracy = 0.6904003497595403\n",
      "Area under PR = 0.7689782103134173\n",
      "Area under ROC = 0.6904606154617405\n",
      "Accuracy = 0.6943204365079365\n",
      "Area under PR = 0.7759894355349097\n",
      "Area under ROC = 0.6939676262434082\n",
      "Accuracy = 0.6907371453623098\n",
      "Area under PR = 0.7655298309226914\n",
      "Area under ROC = 0.691090265377512\n",
      "Accuracy = 0.6992219109866169\n",
      "Area under PR = 0.776348738286206\n",
      "Area under ROC = 0.6991761077541239\n",
      "avg accuracy = 0.6934917837990404\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures=600)\n",
    "data = sc.textFile('./data/train.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "kfold_test = data.randomSplit([0.2,0.2,0.2,0.2,0.2])\n",
    "acc_sum = 0\n",
    "for i in range(5):\n",
    "    test_set = kfold_test[i]\n",
    "    combined_set = None\n",
    "    for j in range(5):\n",
    "        if j != i:\n",
    "            if(combined_set != None):\n",
    "                combined_set = combined_set + kfold_test[j]\n",
    "            else:\n",
    "                combined_set = kfold_test[j]\n",
    "\n",
    "    training = combined_set\n",
    "    test = test_set\n",
    "    (acc_val, actual, predication), model = logisticRegression(training, test)\n",
    "    acc_sum = acc_sum + acc_val\n",
    "\n",
    "print(\"avg accuracy = {}\".format(acc_sum/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'black'>6. a. Decision tree Modelling function</font><br/>\n",
    "<font color = 'black'> Train a Decision Tree model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "def decisionTree(parsedData, test_decision_tree, model = None):\n",
    "    if(model == None):\n",
    "        model = DecisionTree.trainClassifier(parsedData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxDepth=5, maxBins=20)\n",
    "    predictions = model.predict(test_decision_tree.map(lambda x: x.features))\n",
    "    predictionAndLabel = predictions.zip(test_decision_tree.map(lambda lp: lp.label))\n",
    "    metrics = MulticlassMetrics(predictionAndLabel)\n",
    "    return displayMetrics(metrics, predictionAndLabel, test_decision_tree), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> Training the model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 6432.  4604.]\n",
      " [ 4044.  6912.]]\n",
      "Accuracy = 0.6067660967624591\n",
      "Precision = 0.6067660967624591\n",
      "Recall = 0.6067660967624591\n",
      "fMeasure = 0.5979918185198959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reducing the features length \n",
    "hashingTF = HashingTF(numFeatures=250)\n",
    "data = sc.textFile('./data/train.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "parsedData, test_decision_tree = data, data.randomSplit([0.3, 0.8])[0]\n",
    "\n",
    "# train using logistic regression\n",
    "(acc_val, actual, predication), model = decisionTree(parsedData, test_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> Testing the model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5877437325905293\n",
      "Area under PR = 0.6908811360413032\n",
      "Area under ROC = 0.5882069907493637\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures=250)\n",
    "testcsv_data = sc.textFile('./data/test.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "(acc_val, actual, predication), model = decisionTree([], testcsv_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'black'> 5 fold validation of a Decision tree model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6038404175988069\n",
      "Area under PR = 0.6945628137256861\n",
      "Area under ROC = 0.6035146013460227\n",
      "Accuracy = 0.6055791843882912\n",
      "Area under PR = 0.7135876420177848\n",
      "Area under ROC = 0.6051795695959857\n",
      "Accuracy = 0.5991864831038799\n",
      "Area under PR = 0.6941113291793948\n",
      "Area under ROC = 0.5990697852425196\n",
      "Accuracy = 0.6034169847925402\n",
      "Area under PR = 0.7076648984786549\n",
      "Area under ROC = 0.6038348193791004\n",
      "Accuracy = 0.6084205250297601\n",
      "Area under PR = 0.6970684464903896\n",
      "Area under ROC = 0.6079916929418651\n",
      "avg accuracy = 0.6040887189826556\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures=200)\n",
    "data = sc.textFile('./data/train.csv', use_unicode=True).map(get_cleaned_tweet)\n",
    "kfold_test = data.randomSplit([0.2,0.2,0.2,0.2,0.2])\n",
    "acc_sum = 0\n",
    "for i in range(5):\n",
    "    test_set = kfold_test[i]\n",
    "    combined_set = None\n",
    "    for j in range(5):\n",
    "        if j != i:\n",
    "            if(combined_set != None):\n",
    "                combined_set = combined_set + kfold_test[j]\n",
    "            else:\n",
    "                combined_set = kfold_test[j]\n",
    "\n",
    "    training = combined_set\n",
    "    test = test_set\n",
    "    (acc_val, actual, predication), model = decisionTree(training, test)\n",
    "    acc_sum = acc_sum + acc_val\n",
    "\n",
    "print(\"avg accuracy = {}\".format(acc_sum/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 correctly predicted tweets:\n",
      "--------------------\n",
      "@faithbabywear Ooooh, what model are you getting??? I have the 40D and LOVE LOVE LOVE LOVE it!\n",
      "@sketchbug Lebron is a hometown hero to me, lol I love the Lakers but let's go Cavs, lol\n",
      "@sklososky Thanks so much!!! ...from one of your *very* happy Kindle2 winners ; ) I was so surprised, fabulous. Thank you! Best, Kathleen\n",
      "@googleio http://twitpic.com/62shi - Yay! Happy place! Place place!  I love Google!\n",
      "@mashable I never did thank you for including me in your Top 100 Twitter Authors! You Rock! (&amp; I New Wave :-D) http://bit.ly/EOrFV\n",
      "\n",
      "Top 5 incorrectly predicted tweets:\n",
      "--------------------\n",
      "Back from seeing 'Star Trek' and 'Night at the Museum.' 'Star Trek' was amazing, but 'Night at the Museum' was; eh.\n",
      "Life?s a bitch? and so is Dick Cheney. #p2 #bipart #tlot #tcot #hhrs #GOP #DNC http://is.gd/DjyQ\n",
      "Monday already. Iran may implode. Kitchen is a disaster. @annagoss seems happy. @sebulous had a nice weekend and @goldpanda is great. whoop.\n",
      "#RantsAndRaves The worst thing about GM (concord / pleasant hill / martinez): is the fucking UAW. ..   http://buzzup.com/4ueb\n",
      "RT @sportsguy33: New Time Warner slogan: \"\"Time Warner, where we make you long for the days before cable.\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures=600)\n",
    "testcsv_data = sc.textFile('./data/test.csv', use_unicode=True).map(lambda line: get_cleaned_tweet(line, True))\n",
    "logistic_model.clearThreshold()\n",
    "predicted_data = testcsv_data.map(lambda p: (float(logistic_model.predict(p[1].features)), (p[1].label, p[0])))\n",
    "top5_correct_tweets = [x[1][1] for x in predicted_data.sortByKey(ascending=False).filter(lambda x: x[1][0] == 1).top(5)]\n",
    "print(\"Top 5 correctly predicted tweets:\")\n",
    "print(\"--------------------\")\n",
    "for tweet in top5_correct_tweets:\n",
    "    print(tweet)\n",
    "\n",
    "print()\n",
    "low5_correct_tweets = [x[1][1] for x in predicted_data.sortByKey(ascending=False).filter(lambda x: x[1][0] == 0).top(5)]\n",
    "print(\"Top 5 incorrectly predicted tweets:\")\n",
    "print(\"--------------------\")\n",
    "for tweet in low5_correct_tweets:\n",
    "    print(tweet)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
